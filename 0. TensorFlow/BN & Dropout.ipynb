{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('.')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow中提供了批归一化与随机失活的API：\n",
    "- ```tf.layers.dropout```\n",
    "- ```tf.layers.batch_normalization```\n",
    "\n",
    "注意这两个操作在网络中的位置，BN层是位于conv操作与act操作之间，即```conv -> BN -> act```；而dropout操作则可以放在act操作之后，即```conv -> BN -> act -> dropout```。\n",
    "\n",
    "一般来说，dropout只会应用在全连接层上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072) (50000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset import load_cifar10\n",
    "\n",
    "train_data,test_data=load_cifar10(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络设计与搭建\n",
    "这里使用的是之前实现的```mini_CNN```。注意在使用```tf.layers.batch_normalization```时有一个坑，跟TF中BN层实现有关，BN层每次训练时会计算得到一个mean与var，但是最后用于预测的mean、var怎么来的呢？是使用移动平均的方法计算得到的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "unit_I = train_data.n_features    # 输入单元数，等于特征数\n",
    "\n",
    "filters = 32    # 卷积核的数量\n",
    "conv_size = (3, 3)    # 卷积核尺寸\n",
    "\n",
    "pool_size = (2, 2)    # 池化核尺寸\n",
    "strides = (2, 2)    # 核移动的步长\n",
    "\n",
    "fc_size = 128\n",
    "\n",
    "unit_O = 10    # 输出单元数，类别数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-7277d81eef57>:11: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-7277d81eef57>:12: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-7277d81eef57>:15: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-7277d81eef57>:36: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-7277d81eef57>:37: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, unit_I])\n",
    "Y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)    # 训练标识位\n",
    "X_img = tf.transpose(tf.reshape(X, [-1, 3, 32, 32]),\n",
    "                     perm=[0, 2, 3, 1])\n",
    "\n",
    "with tf.name_scope('CNN'):\n",
    "    with tf.name_scope('conv1'):\n",
    "        conv1 = tf.layers.conv2d(X_img, filters=filters,\n",
    "                                 kernel_size=conv_size, padding='same',\n",
    "                                 activation=None)\n",
    "        conv1 = tf.layers.batch_normalization(conv1, training=is_training)\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        pooling1 = tf.layers.max_pooling2d(conv1, pool_size=pool_size,\n",
    "                                           strides=strides)\n",
    "\n",
    "    with tf.name_scope('conv2'):\n",
    "        conv2 = tf.layers.conv2d(pooling1, filters=filters,\n",
    "                                 kernel_size=conv_size, padding='same',\n",
    "                                 activation=None)\n",
    "        conv2 = tf.layers.batch_normalization(conv2, training=is_training)\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        pooling2 = tf.layers.max_pooling2d(conv2, pool_size=pool_size,\n",
    "                                           strides=strides)\n",
    "\n",
    "    with tf.name_scope('conv3'):\n",
    "        conv3 = tf.layers.conv2d(pooling2, filters=filters,\n",
    "                                 kernel_size=conv_size, padding='same',\n",
    "                                 activation=None)\n",
    "        conv3 = tf.layers.batch_normalization(conv3, training=is_training)\n",
    "        conv3 = tf.nn.relu(conv3)\n",
    "        pooling3 = tf.layers.max_pooling2d(conv3, pool_size=pool_size,\n",
    "                                           strides=strides)\n",
    "\n",
    "    with tf.name_scope('fc'):\n",
    "        fc = tf.layers.dense(tf.layers.flatten(pooling3),\n",
    "                             fc_size, activation=tf.nn.relu)\n",
    "#         该网络并不深，不需要很大的rate\n",
    "#         fc = tf.layers.dropout(fc, rate=0.1, training=is_training)\n",
    "\n",
    "    logits = tf.layers.dense(fc, unit_O, activation=None)\n",
    "\n",
    "with tf.name_scope('Eval'):\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=Y, logits=logits)\n",
    "    predict = tf.argmax(logits, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predict, Y), tf.float32))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    lr = 1e-3\n",
    "    # 注意这里牵扯到BN层的一个实现原理，BN每次在训练阶段会计算mean跟var\n",
    "    #\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch_loss: 1.0254285335540771, batch_acc: 0.640625\n",
      "epoch: 2, batch_loss: 0.9187150001525879, batch_acc: 0.640625\n",
      "epoch: 3, batch_loss: 0.927048921585083, batch_acc: 0.703125\n",
      "epoch: 5, batch_loss: 0.8170256614685059, batch_acc: 0.703125\n",
      "epoch: 6, batch_loss: 0.6145782470703125, batch_acc: 0.8125\n",
      "epoch: 6, test_acc: 0.6488381624221802\n",
      "epoch: 7, batch_loss: 0.4981405436992645, batch_acc: 0.828125\n",
      "epoch: 8, batch_loss: 0.5179604291915894, batch_acc: 0.796875\n",
      "epoch: 10, batch_loss: 0.4443773329257965, batch_acc: 0.828125\n",
      "epoch: 11, batch_loss: 0.5571237206459045, batch_acc: 0.796875\n",
      "epoch: 12, batch_loss: 0.5267115235328674, batch_acc: 0.84375\n",
      "epoch: 12, test_acc: 0.7114382982254028\n",
      "epoch: 14, batch_loss: 0.2802017331123352, batch_acc: 0.9375\n",
      "epoch: 15, batch_loss: 0.44359830021858215, batch_acc: 0.828125\n",
      "epoch: 16, batch_loss: 0.35668569803237915, batch_acc: 0.875\n",
      "epoch: 17, batch_loss: 0.5140799283981323, batch_acc: 0.828125\n",
      "epoch: 19, batch_loss: 0.329128623008728, batch_acc: 0.875\n",
      "epoch: 19, test_acc: 0.737379789352417\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    epochs = 20\n",
    "\n",
    "    batch_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch_data, batch_labels in train_data.next_batch():\n",
    "            batch_cnt += 1\n",
    "            loss_val, acc_val, _ = sess.run(\n",
    "                [loss, accuracy, train_op], feed_dict={\n",
    "                    X: batch_data,\n",
    "                    Y: batch_labels,\n",
    "                    is_training: True})\n",
    "\n",
    "            # 每1000batch输出一次信息\n",
    "            if (batch_cnt+1) % 1000 == 0:\n",
    "                print('epoch: {}, batch_loss: {}, batch_acc: {}'.format(\n",
    "                    epoch, loss_val, acc_val))\n",
    "\n",
    "            # 每5000batch做一次验证\n",
    "            if (batch_cnt+1) % 5000 == 0:\n",
    "                all_test_acc_val = list()\n",
    "                for test_batch_data, test_batch_labels in test_data.next_batch():\n",
    "                    test_acc_val = sess.run(accuracy, feed_dict={\n",
    "                        X: test_batch_data,\n",
    "                        Y: test_batch_labels,\n",
    "                        is_training: False\n",
    "                    })\n",
    "                    all_test_acc_val.append(test_acc_val)\n",
    "                test_acc = np.mean(all_test_acc_val)\n",
    "                print('epoch: {}, test_acc: {}'.format(epoch, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经测试发现，该网络单纯的使用BN比混合使用BN效果更好，所以在代码中注释掉了dropout层。"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
