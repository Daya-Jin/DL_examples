{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset/text8', 'r', encoding='utf-8') as fd:\n",
    "    words = fd.read().split()\n",
    "    \n",
    "words=words[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "voc_size = 50000    # 词典大小\n",
    "\n",
    "word_cnt = list()\n",
    "word_cnt.extend(Counter(words).most_common(voc_size-1))    # -1为未在记录的词UNK预留一个位置\n",
    "\n",
    "# 映射表，记得把0预留给UNK\n",
    "word2int = {item[0]: idx+1 for idx, item in enumerate(word_cnt)}\n",
    "int2word = {idx+1: item[0] for idx, item in enumerate(word_cnt)}\n",
    "\n",
    "data = list(map(lambda x: word2int.get(x, 0), words))    # 将所有word转成int\n",
    "\n",
    "unk_cnt = len(words)-reduce(lambda x, y: x+y, map(lambda x: x[1], word_cnt))\n",
    "word_cnt.insert(0, ('UNK', unk_cnt))    # 未在记录的词\n",
    "\n",
    "# 为映射表添加UNK\n",
    "word2int['UNK'] = 0\n",
    "int2word[0] = 'UNK'\n",
    "\n",
    "del words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用滑动窗口生成分批数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class WordData:\n",
    "    def __init__(self, words, batch_size=32, cent_offset=2, cont_per_cent=4):\n",
    "        self.words = words\n",
    "        self.batch_size = batch_size\n",
    "        self.cent_offset = cent_offset    # 中心词的在窗口中的idx，即左右窗口的大小\n",
    "        self.cont_per_cent = cont_per_cent    # 每个中心词产生4个上下文，即4个样本\n",
    "\n",
    "        # batch_size是每个中心词产生样本数量的整数倍，这样就保证了每生成一个batch就会改变中心词\n",
    "        assert self.batch_size % self.cont_per_cent == 0\n",
    "        assert self.cont_per_cent <= self.cent_offset*2    # 每个中心词生成样本数应小于等于窗口内的上下文单词数\n",
    "\n",
    "        self.sample_cnt = 0\n",
    "\n",
    "    def next_batch(self):\n",
    "        self.data = list()\n",
    "        self.label = list()\n",
    "\n",
    "        for idx, center_word in enumerate(self.words):\n",
    "            for context_word in self.words[max(0, idx-self.cent_offset):min(idx+self.cent_offset, len(self.words))+1]:\n",
    "                if context_word != center_word:\n",
    "                    self.data.append(center_word)\n",
    "                    self.label.append(context_word)\n",
    "\n",
    "                    self.sample_cnt += 1    # 每生成一个样本进行计数\n",
    "\n",
    "                    if self.sample_cnt == self.batch_size:    # 样本数达到一个batch时抛出\n",
    "                        self.sample_cnt = 0\n",
    "                        yield np.array(self.data), np.array(self.label).reshape((-1, 1))\n",
    "                        self.data = list()\n",
    "                        self.label = list()\n",
    "\n",
    "        # 抛出不足以成批的数据\n",
    "        yield np.array(self.data), np.array(self.label).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7812.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=128\n",
    "\n",
    "train_data=WordData(data)\n",
    "len(data)/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_I = 1    # 单个数字表示的word\n",
    "emb_size = 128\n",
    "unit_O = 1\n",
    "\n",
    "neg_samples = 10    # 负采样参数\n",
    "valid_size = 16  # Random set of words to evaluate similarity on.\n",
    "valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "valid_examples = np.random.choice(valid_window, valid_size, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "X = tf.placeholder(tf.int32, shape=[None])\n",
    "Y = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "with tf.name_scope('Emb'):\n",
    "    emb = tf.Variable(tf.random_uniform([voc_size, emb_size], -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(emb, X)\n",
    "\n",
    "with tf.name_scope('Eval'):\n",
    "    nce_weights = tf.Variable(tf.truncated_normal([voc_size, emb_size],\n",
    "                                                  stddev=1.0 / math.sqrt(emb_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([voc_size]))\n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,\n",
    "                                         biases=nce_biases,\n",
    "                                         labels=Y,\n",
    "                                         inputs=embed,\n",
    "                                         num_sampled=neg_samples,\n",
    "                                         num_classes=voc_size))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "\n",
    "with tf.name_scope('Valid'):\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(emb), 1, keepdims=True))\n",
    "    norm_emb = emb / norm\n",
    "    valid_emb = tf.nn.embedding_lookup(norm_emb, valid_dataset)\n",
    "    similarity = tf.matmul(valid_emb, norm_emb, transpose_b=True)\n",
    "\n",
    "init = tf.global_variables_initializer()    # 所有变量初始化\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True    # 按需使用显存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch_loss: 13.46476936340332\n",
      "epoch: 1, batch_loss: 24.948165893554688\n",
      "epoch: 1, batch_loss: 35.9627799987793\n",
      "epoch: 1, batch_loss: 4.226629257202148\n",
      "epoch: 1, batch_loss: 15.40259075164795\n",
      "Nearest to had: was became he has into\n",
      "Nearest to for: which as of by such\n",
      "Nearest to being: are has been since often\n",
      "Nearest to new: national history reportedly the states\n",
      "Nearest to and: the was such zero study\n",
      "Nearest to two: five six three zero eight\n",
      "Nearest to i: when s not about was\n",
      "Nearest to UNK: australia its this eight such\n",
      "Nearest to up: linemen pacific children dedicated t\n",
      "Nearest to were: are people he had was\n",
      "Nearest to them: not fixed flight any central\n",
      "Nearest to use: history suez find tend possible\n",
      "Nearest to called: such two language sanctioned known\n",
      "Nearest to th: three seven eight six five\n",
      "Nearest to six: three five eight seven four\n",
      "Nearest to was: had where and became were\n",
      "epoch: 1, batch_loss: 4.229766368865967\n",
      "epoch: 1, batch_loss: 7.380623817443848\n",
      "epoch: 1, batch_loss: 4.784083843231201\n",
      "epoch: 1, batch_loss: 4.069324493408203\n",
      "epoch: 1, batch_loss: 5.9014387130737305\n",
      "Nearest to had: has having achilles have were\n",
      "Nearest to for: while of since name general\n",
      "Nearest to being: was were the much both\n",
      "Nearest to new: allah including energy states city\n",
      "Nearest to and: among modern much at if\n",
      "Nearest to two: four six that eight seven\n",
      "Nearest to i: that if now t abortion\n",
      "Nearest to UNK: united book australia novel she\n",
      "Nearest to up: character returned have hoped having\n",
      "Nearest to were: was are both being however\n",
      "Nearest to them: still even said name used\n",
      "Nearest to use: name both now modern s\n",
      "Nearest to called: later is now character publicly\n",
      "Nearest to th: eight six seven isbn borden\n",
      "Nearest to six: seven eight two five three\n",
      "Nearest to was: were being is all himself\n",
      "epoch: 1, batch_loss: 4.3121337890625\n",
      "epoch: 1, batch_loss: 6.156438827514648\n",
      "epoch: 2, batch_loss: 4.210519313812256\n",
      "epoch: 2, batch_loss: 4.361554145812988\n",
      "epoch: 2, batch_loss: 4.349275588989258\n",
      "Nearest to had: has have through without by\n",
      "Nearest to for: will by under at has\n",
      "Nearest to being: usually even most zero is\n",
      "Nearest to new: east court australia york states\n",
      "Nearest to and: in but six population three\n",
      "Nearest to two: three six nine zero one\n",
      "Nearest to i: if you zero believe did\n",
      "Nearest to UNK: work field power river found\n",
      "Nearest to up: down states came work now\n",
      "Nearest to were: are being has is but\n",
      "Nearest to them: further two people control that\n",
      "Nearest to use: church all part cypress court\n",
      "Nearest to called: made song album ore since\n",
      "Nearest to th: nine two zero five six\n",
      "Nearest to six: nine zero two three five\n",
      "Nearest to was: has being himself through zero\n",
      "epoch: 2, batch_loss: 4.89140510559082\n",
      "epoch: 2, batch_loss: 7.220771312713623\n",
      "epoch: 2, batch_loss: 3.199810028076172\n",
      "epoch: 2, batch_loss: 3.1331119537353516\n",
      "epoch: 2, batch_loss: 3.8309669494628906\n",
      "Nearest to had: have has into was him\n",
      "Nearest to for: under since most rushers it\n",
      "Nearest to being: was are australia him came\n",
      "Nearest to new: history following where one city\n",
      "Nearest to and: or UNK in however art\n",
      "Nearest to two: eight three seven four isbn\n",
      "Nearest to i: you believe abortion do algorithm\n",
      "Nearest to UNK: one d six arsenic german\n",
      "Nearest to up: it which power not them\n",
      "Nearest to were: are being some their have\n",
      "Nearest to them: all him right either not\n",
      "Nearest to use: where form because side end\n",
      "Nearest to called: poet used human murdered injury\n",
      "Nearest to th: five seven six zero three\n",
      "Nearest to six: eight seven three zero four\n",
      "Nearest to was: being is had into became\n",
      "epoch: 2, batch_loss: 2.866619110107422\n",
      "epoch: 2, batch_loss: 3.197329044342041\n",
      "epoch: 2, batch_loss: 3.381652355194092\n",
      "epoch: 2, batch_loss: 3.281684160232544\n",
      "epoch: 3, batch_loss: 3.49613618850708\n",
      "Nearest to had: have lost never been has\n",
      "Nearest to for: through over during however on\n",
      "Nearest to being: ilk as by line warhol\n",
      "Nearest to new: range australia northern mind and\n",
      "Nearest to and: in through to by making\n",
      "Nearest to two: four three nine five six\n",
      "Nearest to i: ii what you t they\n",
      "Nearest to UNK: work country jews indicating chlororhynchos\n",
      "Nearest to up: person out probably them acyclic\n",
      "Nearest to were: are was many several have\n",
      "Nearest to them: either himself work people once\n",
      "Nearest to use: form person people way particular\n",
      "Nearest to called: there made what built named\n",
      "Nearest to th: nine six five three seven\n",
      "Nearest to six: seven five three four zero\n",
      "Nearest to was: is became by were lincoln\n",
      "epoch: 3, batch_loss: 3.2031867504119873\n",
      "epoch: 3, batch_loss: 3.0270912647247314\n",
      "epoch: 3, batch_loss: 3.8195152282714844\n",
      "epoch: 3, batch_loss: 4.92290735244751\n",
      "epoch: 3, batch_loss: 3.9844727516174316\n",
      "Nearest to had: has have developed established lost\n",
      "Nearest to for: offroad as even analysis in\n",
      "Nearest to being: they generally he be plan\n",
      "Nearest to new: city york england chief australia\n",
      "Nearest to and: in become human teaching however\n",
      "Nearest to two: three four isbn five century\n",
      "Nearest to i: you t they say f\n",
      "Nearest to UNK: culture achilles conduct both pictures\n",
      "Nearest to up: back do use returned place\n",
      "Nearest to were: are once was despite in\n",
      "Nearest to them: him england much do vote\n",
      "Nearest to use: support case south ability exist\n",
      "Nearest to called: probably here architectural although given\n",
      "Nearest to th: four rd eight nd nine\n",
      "Nearest to six: five seven four eight nine\n",
      "Nearest to was: be is are published though\n",
      "epoch: 3, batch_loss: 3.393667459487915\n",
      "epoch: 3, batch_loss: 3.876682758331299\n",
      "epoch: 3, batch_loss: 3.1717617511749268\n",
      "epoch: 3, batch_loss: 2.4472126960754395\n",
      "epoch: 3, batch_loss: 2.788241147994995\n",
      "Nearest to had: has himself before have must\n",
      "Nearest to for: s binds open matters modern\n",
      "Nearest to being: workspace view were any be\n",
      "Nearest to new: magazine comparison atlantic york close\n",
      "Nearest to and: father lincoln later in spain\n",
      "Nearest to two: five four one c azo\n",
      "Nearest to i: e t you know do\n",
      "Nearest to UNK: set ball made aarberg ammoniac\n",
      "Nearest to up: him time me agassi generally\n",
      "Nearest to were: are is be many families\n",
      "Nearest to them: him come play vote children\n",
      "Nearest to use: common part period course sense\n",
      "Nearest to called: keener regarded defined used autistic\n",
      "Nearest to th: four seven births eight december\n",
      "Nearest to six: zero eight nine five four\n",
      "Nearest to was: is first being biographers time\n",
      "epoch: 3, batch_loss: 1.2767584323883057\n",
      "epoch: 3, batch_loss: 3.326843500137329\n",
      "epoch: 4, batch_loss: 3.44604754447937\n",
      "epoch: 4, batch_loss: 2.6204025745391846\n",
      "epoch: 4, batch_loss: 1.6585876941680908\n",
      "Nearest to had: was has once he did\n",
      "Nearest to for: dutton that these wiki scientific\n",
      "Nearest to being: person result apl though is\n",
      "Nearest to new: local churchmen line radio technology\n",
      "Nearest to and: on of engine although inflict\n",
      "Nearest to two: six seven five eight three\n",
      "Nearest to i: you t says ii jews\n",
      "Nearest to UNK: scottish m ostracism und caria\n",
      "Nearest to up: back down returned led continued\n",
      "Nearest to were: are still have themselves is\n",
      "Nearest to them: points nature misrepresent him performed\n",
      "Nearest to use: because half subject construction side\n",
      "Nearest to called: known named considered built regarded\n",
      "Nearest to th: seven bc century eight empaytaz\n",
      "Nearest to six: two seven nine five c\n",
      "Nearest to was: had though he is wrote\n",
      "epoch: 4, batch_loss: 2.9331064224243164\n",
      "epoch: 4, batch_loss: 3.1413121223449707\n",
      "epoch: 4, batch_loss: 3.3355984687805176\n",
      "epoch: 4, batch_loss: 3.3389244079589844\n",
      "epoch: 4, batch_loss: 2.6921074390411377\n",
      "Nearest to had: has he would until inkwell\n",
      "Nearest to for: within of on makes became\n",
      "Nearest to being: was time hitler paulus is\n",
      "Nearest to new: york church boat americas uris\n",
      "Nearest to and: the of from in australia\n",
      "Nearest to two: five four eight three six\n",
      "Nearest to i: ii t me p they\n",
      "Nearest to UNK: from alexander judaism sydenham washington\n",
      "Nearest to up: once just man eventually he\n",
      "Nearest to were: are rushers several being many\n",
      "Nearest to them: individuals people him binds jesus\n",
      "Nearest to use: instead awareness east laws exist\n",
      "Nearest to called: considered but built referred described\n",
      "Nearest to th: seven eight six three bc\n",
      "Nearest to six: seven four eight three nine\n",
      "Nearest to was: being is vomited became australia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, batch_loss: 3.6077609062194824\n",
      "epoch: 4, batch_loss: 1.0354843139648438\n",
      "epoch: 4, batch_loss: 3.894710063934326\n",
      "epoch: 4, batch_loss: 4.2480974197387695\n",
      "epoch: 5, batch_loss: 2.977494478225708\n",
      "Nearest to had: has have were since thus\n",
      "Nearest to for: example on within next machine\n",
      "Nearest to being: both while identify people him\n",
      "Nearest to new: york canada england australian usa\n",
      "Nearest to and: beyond towards galt world throughout\n",
      "Nearest to two: five three four seven six\n",
      "Nearest to i: you me ii just t\n",
      "Nearest to UNK: story pole bulleri institutions writing\n",
      "Nearest to up: while germany sacrifice out he\n",
      "Nearest to were: was are had himself been\n",
      "Nearest to them: individual him up people individuals\n",
      "Nearest to use: against addition or account name\n",
      "Nearest to called: essentially held subpoenaed formed means\n",
      "Nearest to th: rd seven eight zero births\n",
      "Nearest to six: four three five seven two\n",
      "Nearest to was: were translation himself are been\n",
      "epoch: 5, batch_loss: 3.642193078994751\n",
      "epoch: 5, batch_loss: 4.135936737060547\n",
      "epoch: 5, batch_loss: 2.894796133041382\n",
      "epoch: 5, batch_loss: 3.1866447925567627\n",
      "epoch: 5, batch_loss: 2.1899890899658203\n",
      "Nearest to had: having has have may or\n",
      "Nearest to for: terminal body within as after\n",
      "Nearest to being: ashoka they material those waterhouse\n",
      "Nearest to new: story a matter york learning\n",
      "Nearest to and: feature produce abasciano science scrolling\n",
      "Nearest to two: three six seven five each\n",
      "Nearest to i: you ii says me t\n",
      "Nearest to UNK: experiential religion stories works chattahoochee\n",
      "Nearest to up: dion returned again minutes just\n",
      "Nearest to were: are cities events mingling include\n",
      "Nearest to them: words vote ways individuals affirm\n",
      "Nearest to use: tribe knowledge aware because exist\n",
      "Nearest to called: considered named given unclear regarded\n",
      "Nearest to th: seven eight st six rd\n",
      "Nearest to six: five seven eight zero million\n",
      "Nearest to was: is became once be made\n",
      "epoch: 5, batch_loss: 3.483468532562256\n",
      "epoch: 5, batch_loss: 4.107318878173828\n",
      "epoch: 5, batch_loss: 3.387120008468628\n",
      "epoch: 5, batch_loss: 2.950169563293457\n",
      "epoch: 5, batch_loss: 4.362445831298828\n",
      "Nearest to had: have has been having he\n",
      "Nearest to for: today as more pleaded unharmed\n",
      "Nearest to being: capita rushers is goal elmina\n",
      "Nearest to new: york zealand australia city canada\n",
      "Nearest to and: with in working repaint of\n",
      "Nearest to two: three six one million five\n",
      "Nearest to i: me iii crystallization andorra why\n",
      "Nearest to UNK: snuff m mixture field chamique\n",
      "Nearest to up: light seven him one out\n",
      "Nearest to were: are became europeans had equivalently\n",
      "Nearest to them: him stand be back ways\n",
      "Nearest to use: delineates development course outer anchor\n",
      "Nearest to called: named termed regarded considered where\n",
      "Nearest to th: bc approximately century about three\n",
      "Nearest to six: seven two four three five\n",
      "Nearest to was: is became wrote has makes\n",
      "epoch: 5, batch_loss: 2.2048497200012207\n",
      "epoch: 6, batch_loss: 2.7453534603118896\n",
      "epoch: 6, batch_loss: 3.8102548122406006\n",
      "epoch: 6, batch_loss: 3.3646016120910645\n",
      "epoch: 6, batch_loss: 3.1090824604034424\n",
      "Nearest to had: has have having never already\n",
      "Nearest to for: while aikidoka receive their premierships\n",
      "Nearest to being: binds peacemaker colloid but atheistic\n",
      "Nearest to new: wave york heavily debate scientific\n",
      "Nearest to and: of in exemplify becomes the\n",
      "Nearest to two: three about nine ft five\n",
      "Nearest to i: you ii everybody iii does\n",
      "Nearest to UNK: surface name enemies o monetary\n",
      "Nearest to up: function dion according one back\n",
      "Nearest to were: are many their both various\n",
      "Nearest to them: individuals ways themselves these efforts\n",
      "Nearest to use: term past things antimatter technik\n",
      "Nearest to called: named known sa always unclear\n",
      "Nearest to th: seven five eight deaths nine\n",
      "Nearest to six: four eight five seven three\n",
      "Nearest to was: is be but its became\n",
      "epoch: 6, batch_loss: 3.66416072845459\n",
      "epoch: 6, batch_loss: 3.429434061050415\n",
      "epoch: 6, batch_loss: 2.4922430515289307\n",
      "epoch: 6, batch_loss: 3.0519676208496094\n",
      "epoch: 6, batch_loss: 2.687492847442627\n",
      "Nearest to had: have has having was until\n",
      "Nearest to for: exploding in could rigel should\n",
      "Nearest to being: early time entire christianity taking\n",
      "Nearest to new: york australia london city east\n",
      "Nearest to and: like appeals as of on\n",
      "Nearest to two: three five six seven eight\n",
      "Nearest to i: ii iii e fernando vegetarians\n",
      "Nearest to UNK: nominee lawmaking physics movie sneader\n",
      "Nearest to up: came returned him when to\n",
      "Nearest to were: are rushers be was being\n",
      "Nearest to them: him forced individuals jesus me\n",
      "Nearest to use: history things exist stream study\n",
      "Nearest to called: weidenfeld termed orlovsky keener displace\n",
      "Nearest to th: six four three century seven\n",
      "Nearest to six: four seven three five th\n",
      "Nearest to was: is took she had adjourned\n",
      "epoch: 6, batch_loss: 3.0925426483154297\n",
      "epoch: 6, batch_loss: 3.030733823776245\n",
      "epoch: 6, batch_loss: 5.501434326171875\n",
      "epoch: 6, batch_loss: 4.902715682983398\n",
      "epoch: 7, batch_loss: 3.5095086097717285\n",
      "Nearest to had: has have already having never\n",
      "Nearest to for: ancestry jeep within unharmed remove\n",
      "Nearest to being: was is often are detail\n",
      "Nearest to new: epitomes york smallest circular early\n",
      "Nearest to and: of dispensation economics trolling populations\n",
      "Nearest to two: nella toxic retirees minor stirring\n",
      "Nearest to i: you we periods know intervene\n",
      "Nearest to UNK: work philosophical related doctrine musch\n",
      "Nearest to up: men out down crew dion\n",
      "Nearest to were: was been many chattahoochee temptation\n",
      "Nearest to them: personal him ways arguments face\n",
      "Nearest to use: history time addition however support\n",
      "Nearest to called: named granted metropolitans iaijutsu followed\n",
      "Nearest to th: eight rd nine mid january\n",
      "Nearest to six: seven eight four three five\n",
      "Nearest to was: is being were has mingling\n",
      "epoch: 7, batch_loss: 3.920693874359131\n",
      "epoch: 7, batch_loss: 2.006507396697998\n",
      "epoch: 7, batch_loss: 2.4932668209075928\n",
      "epoch: 7, batch_loss: 2.1421189308166504\n",
      "epoch: 7, batch_loss: 2.2433888912200928\n",
      "Nearest to had: has have having countries suggested\n",
      "Nearest to for: and however with of when\n",
      "Nearest to being: veniaminov pidgin valuable greenlip find\n",
      "Nearest to new: york zealand jersey states california\n",
      "Nearest to and: with are for in a\n",
      "Nearest to two: four five of km that\n",
      "Nearest to i: you ii your we if\n",
      "Nearest to UNK: directories extensions valdes psychedelics brewster\n",
      "Nearest to up: one read they nine value\n",
      "Nearest to were: are have is many residing\n",
      "Nearest to them: him she objects either barrett\n",
      "Nearest to use: include element need purpose problem\n",
      "Nearest to called: used termed mentioned raised known\n",
      "Nearest to th: century nine five seven oilcrops\n",
      "Nearest to six: five nine eight three seven\n",
      "Nearest to was: is became allows invented bishoprics\n",
      "epoch: 7, batch_loss: 3.5954360961914062\n",
      "epoch: 7, batch_loss: 3.2687175273895264\n",
      "epoch: 7, batch_loss: 3.347841262817383\n",
      "epoch: 7, batch_loss: 2.92210054397583\n",
      "epoch: 7, batch_loss: 2.8296940326690674\n",
      "Nearest to had: has must been was have\n",
      "Nearest to for: hercule rushers calwell palpebrata fractured\n",
      "Nearest to being: is was mabillon are length\n",
      "Nearest to new: york university zealand canada buffalo\n",
      "Nearest to and: the in algeria christian beads\n",
      "Nearest to two: five six four three zero\n",
      "Nearest to i: god ii iii iv honorific\n",
      "Nearest to UNK: manchu jews pidgin holy abigail\n",
      "Nearest to up: put them him antifa novel\n",
      "Nearest to were: several are numerous contigents none\n",
      "Nearest to them: return remain down past up\n",
      "Nearest to use: books view term satisfaction jews\n",
      "Nearest to called: termed named adopted regarded anonymously\n",
      "Nearest to th: rd approximately nine eight august\n",
      "Nearest to six: eight two four three seven\n",
      "Nearest to was: a being iliuliuk is had\n",
      "epoch: 7, batch_loss: 1.3267216682434082\n",
      "epoch: 8, batch_loss: 3.4486570358276367\n",
      "epoch: 8, batch_loss: 1.4711997509002686\n",
      "epoch: 8, batch_loss: 2.9186360836029053\n",
      "epoch: 8, batch_loss: 2.2918925285339355\n",
      "Nearest to had: has have already been never\n",
      "Nearest to for: as if good canceled adh\n",
      "Nearest to being: were beings them those discogs\n",
      "Nearest to new: soumer york houseful unwilling muttered\n",
      "Nearest to and: or in is however six\n",
      "Nearest to two: three eight six four crew\n",
      "Nearest to i: you politicians iii everybody tiles\n",
      "Nearest to UNK: official other husserl echinoderms donovan\n",
      "Nearest to up: victories efforts dion aslian due\n",
      "Nearest to were: being are minor none acafest\n",
      "Nearest to them: being electrons beings saddle structures\n",
      "Nearest to use: exception russian begin asexual interaction\n",
      "Nearest to called: named required known considered surrounded\n",
      "Nearest to th: five july seven november nd\n",
      "Nearest to six: seven eight four three five\n",
      "Nearest to was: is fechter frigatebird aclis may\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, batch_loss: 3.0253043174743652\n",
      "epoch: 8, batch_loss: 2.8150570392608643\n",
      "epoch: 8, batch_loss: 2.015658140182495\n",
      "epoch: 8, batch_loss: 2.1830825805664062\n",
      "epoch: 8, batch_loss: 2.0545730590820312\n",
      "Nearest to had: has been have knew having\n",
      "Nearest to for: perilous musculoskeletal with replica facing\n",
      "Nearest to being: were taliban together beings mabillon\n",
      "Nearest to new: york myths similarly wide uganda\n",
      "Nearest to and: in as of a books\n",
      "Nearest to two: eight four six zero five\n",
      "Nearest to i: you we ever xn ii\n",
      "Nearest to UNK: lawmaking bret mk handke theory\n",
      "Nearest to up: them shaferi dion him octavian\n",
      "Nearest to were: are became having being some\n",
      "Nearest to them: him closer up nutmeg individuals\n",
      "Nearest to use: proper hebrew finding original name\n",
      "Nearest to called: defined musculoskeletal known regarded viewed\n",
      "Nearest to th: eight march four century st\n",
      "Nearest to six: four eight five seven zero\n",
      "Nearest to was: is became were cultriformis dice\n",
      "epoch: 8, batch_loss: 2.9983439445495605\n",
      "epoch: 8, batch_loss: 3.8982725143432617\n",
      "epoch: 8, batch_loss: 2.1743521690368652\n",
      "epoch: 9, batch_loss: 2.805985450744629\n",
      "epoch: 9, batch_loss: 3.9017832279205322\n",
      "Nearest to had: have has having already been\n",
      "Nearest to for: outside radio before building of\n",
      "Nearest to being: beings men wane thus shahrastani\n",
      "Nearest to new: south australia restaurateurs massachusetts china\n",
      "Nearest to and: of in for islands online\n",
      "Nearest to two: past course retrieved three one\n",
      "Nearest to i: ii you iii xn translucent\n",
      "Nearest to UNK: musch astronaut asteroid powell algebra\n",
      "Nearest to up: put continued over generally dion\n",
      "Nearest to were: are have away was both\n",
      "Nearest to them: communicate him back directly saddle\n",
      "Nearest to use: jainism expansion question leftover idea\n",
      "Nearest to called: based adopted used iaijutsu followed\n",
      "Nearest to th: nd july january five february\n",
      "Nearest to six: three seven five eight births\n",
      "Nearest to was: has is became be irish\n",
      "epoch: 9, batch_loss: 3.111477851867676\n",
      "epoch: 9, batch_loss: 2.4884238243103027\n",
      "epoch: 9, batch_loss: 3.9885213375091553\n",
      "epoch: 9, batch_loss: 2.174614429473877\n",
      "epoch: 9, batch_loss: 3.7980871200561523\n",
      "Nearest to had: have has gage having with\n",
      "Nearest to for: multiplicativeness infringing netborger most with\n",
      "Nearest to being: funneled account liberalisation dressed contract\n",
      "Nearest to new: york oklahoma australia attiko bolivia\n",
      "Nearest to and: a of cannes controlled in\n",
      "Nearest to two: four three six one eight\n",
      "Nearest to i: you they we moses so\n",
      "Nearest to UNK: scrupulous oratory chattahoochee related overfarmed\n",
      "Nearest to up: dion cruentis wages generally lbf\n",
      "Nearest to were: bail live was residing are\n",
      "Nearest to them: structures ones saddle him thought\n",
      "Nearest to use: display prokaryotes form newcomers addition\n",
      "Nearest to called: known viewed referred considered alcamenes\n",
      "Nearest to th: century bc nd rd six\n",
      "Nearest to six: eight two four metres five\n",
      "Nearest to was: is were oav strategically stoney\n",
      "epoch: 9, batch_loss: 3.2284810543060303\n",
      "epoch: 9, batch_loss: 2.8302359580993652\n",
      "epoch: 9, batch_loss: 2.381396770477295\n",
      "epoch: 9, batch_loss: 2.6591548919677734\n",
      "epoch: 9, batch_loss: 4.405545234680176\n",
      "Nearest to had: been having have he was\n",
      "Nearest to for: of pidgin that as jeep\n",
      "Nearest to being: were inflow having operational hydrogens\n",
      "Nearest to new: knopf papua zealand york breasts\n",
      "Nearest to and: the a avenge in musch\n",
      "Nearest to two: four seven three gnomon pieces\n",
      "Nearest to i: you iii e t ii\n",
      "Nearest to UNK: name sohmer greenlip intercession father\n",
      "Nearest to up: out take dion put together\n",
      "Nearest to were: are being been books his\n",
      "Nearest to them: memnoch pacifying moon her careful\n",
      "Nearest to use: term books newcomers addition notation\n",
      "Nearest to called: named if feasibility drawn confirmed\n",
      "Nearest to th: june km nd december five\n",
      "Nearest to six: three four eight five april\n",
      "Nearest to was: is has had been play\n",
      "epoch: 9, batch_loss: 3.352311372756958\n",
      "epoch: 10, batch_loss: 4.238435745239258\n",
      "epoch: 10, batch_loss: 4.865532875061035\n",
      "epoch: 10, batch_loss: 2.193772077560425\n",
      "epoch: 10, batch_loss: 4.514087200164795\n",
      "Nearest to had: has have been were already\n",
      "Nearest to for: is or of objections a\n",
      "Nearest to being: or exists confessors like physiographic\n",
      "Nearest to new: york orleans anchor this suction\n",
      "Nearest to and: or which if on anisotropic\n",
      "Nearest to two: six one five three or\n",
      "Nearest to i: e you any won intricacies\n",
      "Nearest to UNK: donovan semigroup materna paced stol\n",
      "Nearest to up: move or dion players who\n",
      "Nearest to were: was are had have emanate\n",
      "Nearest to them: stab inhibition appraised communicate him\n",
      "Nearest to use: produce make tasks absence part\n",
      "Nearest to called: considered attributed known granted characteristic\n",
      "Nearest to th: eight nine isbn bc mm\n",
      "Nearest to six: five eight four two or\n",
      "Nearest to was: is were play south be\n",
      "epoch: 10, batch_loss: 3.128147602081299\n",
      "epoch: 10, batch_loss: 1.6174747943878174\n",
      "epoch: 10, batch_loss: 1.7170590162277222\n",
      "epoch: 10, batch_loss: 2.650850534439087\n",
      "epoch: 10, batch_loss: 4.079002857208252\n",
      "Nearest to had: having scruple has said have\n",
      "Nearest to for: community cosmologists until taking commisssioner\n",
      "Nearest to being: were spaceflights rushers tisch apostelgeschichten\n",
      "Nearest to new: oklahoma york zealand los etiology\n",
      "Nearest to and: in of shimura the bridge\n",
      "Nearest to two: four nine five six one\n",
      "Nearest to i: ii intervene t crystallization iii\n",
      "Nearest to UNK: boudewijn buddha pharmacological polarity ulrich\n",
      "Nearest to up: open back attempt docked me\n",
      "Nearest to were: are domination was falsify became\n",
      "Nearest to them: him together we things years\n",
      "Nearest to use: addition newcomers part warrantless proper\n",
      "Nearest to called: orlovsky small surrounds android grapnel\n",
      "Nearest to th: january five eight century nd\n",
      "Nearest to six: four five two april nine\n",
      "Nearest to was: is her came were the\n",
      "epoch: 10, batch_loss: 2.6803736686706543\n",
      "epoch: 10, batch_loss: 3.2098419666290283\n",
      "epoch: 10, batch_loss: 2.989912986755371\n",
      "epoch: 11, batch_loss: 2.4257569313049316\n",
      "epoch: 11, batch_loss: 3.589545726776123\n",
      "Nearest to had: gave has having must thission\n",
      "Nearest to for: bsl later disregarded to lxxxix\n",
      "Nearest to being: is was often posterity beneficially\n",
      "Nearest to new: prosperous incriminating papua vista york\n",
      "Nearest to and: the in language leningrad of\n",
      "Nearest to two: one seven five three nine\n",
      "Nearest to i: cleeton iii dick myself ii\n",
      "Nearest to UNK: greenlip blarer investment beloved team\n",
      "Nearest to up: put product pass them successful\n",
      "Nearest to were: are ontology cabbalists hbr distinct\n",
      "Nearest to them: him succeed logia face contact\n",
      "Nearest to use: ballistics version idea destruction absence\n",
      "Nearest to called: iaijutsu made which metropolitans bound\n",
      "Nearest to th: nd seven bc five eight\n",
      "Nearest to six: four zero five nine seven\n",
      "Nearest to was: being entanglement came artemis is\n",
      "epoch: 11, batch_loss: 3.380662441253662\n",
      "epoch: 11, batch_loss: 3.1254258155822754\n",
      "epoch: 11, batch_loss: 2.9968202114105225\n",
      "epoch: 11, batch_loss: 3.1552810668945312\n",
      "epoch: 11, batch_loss: 3.417529344558716\n",
      "Nearest to had: has having successor have dunmore\n",
      "Nearest to for: sidewise planata infringing responsiveness to\n",
      "Nearest to being: death pidgin them play acounting\n",
      "Nearest to new: buffalo extensive mongolian biomedical york\n",
      "Nearest to and: mineralized lapland two in smoothed\n",
      "Nearest to two: four one seven three five\n",
      "Nearest to i: you t polynomial we embrace\n",
      "Nearest to UNK: fano wissowa ksu audio fatu\n",
      "Nearest to up: down them put alia parallel\n",
      "Nearest to were: had was cecrops been are\n",
      "Nearest to them: work hitler up being concept\n",
      "Nearest to use: tasks favour reputedly exist make\n",
      "Nearest to called: bound allowed considered formed visible\n",
      "Nearest to th: nd five century nine nubians\n",
      "Nearest to six: five seven eight april three\n",
      "Nearest to was: had became sligo were is\n",
      "epoch: 11, batch_loss: 2.8396427631378174\n",
      "epoch: 11, batch_loss: 2.5502326488494873\n",
      "epoch: 11, batch_loss: 3.4231650829315186\n",
      "epoch: 11, batch_loss: 1.7285752296447754\n",
      "epoch: 11, batch_loss: 3.235727548599243\n",
      "Nearest to had: might been has was knew\n",
      "Nearest to for: on after before while in\n",
      "Nearest to being: australische himself after adasaurus are\n",
      "Nearest to new: york zealand oregon london canada\n",
      "Nearest to and: trade of the in orman\n",
      "Nearest to two: nine one four three six\n",
      "Nearest to i: ii toinn iii iv diametrically\n",
      "Nearest to UNK: panarchy law rummaged prophets mudarra\n",
      "Nearest to up: put down ensured him promise\n",
      "Nearest to were: are was been had be\n",
      "Nearest to them: way gotthard occupation him judaism\n",
      "Nearest to use: versions newcomers source laws everyday\n",
      "Nearest to called: named arrived did formed built\n",
      "Nearest to th: rd century nd november womanly\n",
      "Nearest to six: seven three four five zero\n",
      "Nearest to was: were is had be has\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, batch_loss: 3.199989080429077\n",
      "epoch: 12, batch_loss: 4.404428482055664\n",
      "epoch: 12, batch_loss: 3.515326499938965\n",
      "epoch: 12, batch_loss: 2.803966522216797\n",
      "epoch: 12, batch_loss: 2.7001166343688965\n",
      "Nearest to had: have would knew scrutinized umpires\n",
      "Nearest to for: xn and as after book\n",
      "Nearest to being: peacemaker alarmed freeing often were\n",
      "Nearest to new: york gecko approbation prothrombin frightening\n",
      "Nearest to and: was with in for as\n",
      "Nearest to two: six three eight five bayerischen\n",
      "Nearest to i: iii t tiles you just\n",
      "Nearest to UNK: merican revolutionaries reprising jordana sui\n",
      "Nearest to up: wants yards right reaches down\n",
      "Nearest to were: are was is being so\n",
      "Nearest to them: way him contract men statements\n",
      "Nearest to use: warrantless tasks manufacture multitude refer\n",
      "Nearest to called: named bound tamarack widget known\n",
      "Nearest to th: nd nine eight seven six\n",
      "Nearest to six: eight nine zero four seven\n",
      "Nearest to was: is were and as play\n",
      "epoch: 12, batch_loss: 2.3978049755096436\n",
      "epoch: 12, batch_loss: 2.276620626449585\n",
      "epoch: 12, batch_loss: 3.480571746826172\n",
      "epoch: 12, batch_loss: 2.288586378097534\n",
      "epoch: 12, batch_loss: 2.244643449783325\n",
      "Nearest to had: rejects knew did himself before\n",
      "Nearest to for: with dipl haggada as pages\n",
      "Nearest to being: were eastern purusha rwanda indefinitely\n",
      "Nearest to new: york oregon different oklahoma free\n",
      "Nearest to and: of omori variability constructivists warranty\n",
      "Nearest to two: three five eight zero bytes\n",
      "Nearest to i: iii ii iv tiles toinn\n",
      "Nearest to UNK: fredericksburg nominee keyes grierson wright\n",
      "Nearest to up: put way them addition down\n",
      "Nearest to were: are administrative being rushers have\n",
      "Nearest to them: up attention effort him jesus\n",
      "Nearest to use: newcomers addition transcriptions apply make\n",
      "Nearest to called: named drawn apalunas topsoil enquirer\n",
      "Nearest to th: century st nd bce millennium\n",
      "Nearest to six: eight three zero four seven\n",
      "Nearest to was: is notate been were heme\n",
      "epoch: 12, batch_loss: 3.086498975753784\n",
      "epoch: 12, batch_loss: 3.4740872383117676\n",
      "epoch: 12, batch_loss: 3.95756459236145\n",
      "epoch: 13, batch_loss: 2.5366415977478027\n",
      "epoch: 13, batch_loss: 3.4071526527404785\n",
      "Nearest to had: has would never have been\n",
      "Nearest to for: of and to dutton adh\n",
      "Nearest to being: be material complements figure australische\n",
      "Nearest to new: york local cairngorms scientific the\n",
      "Nearest to and: of concerns he the walkers\n",
      "Nearest to two: one eight five three nine\n",
      "Nearest to i: ii we unfortunately rxd would\n",
      "Nearest to UNK: wadden also issues mulundo craters\n",
      "Nearest to up: bound down unable taxed rollie\n",
      "Nearest to were: are themselves pontius unalaska almighty\n",
      "Nearest to them: permitted face trying actually going\n",
      "Nearest to use: application jainism destruction technik call\n",
      "Nearest to called: named available attributed hutten tenetur\n",
      "Nearest to th: nd three seven five zero\n",
      "Nearest to six: seven one five three zero\n",
      "Nearest to was: became ataulf be iliuliuk photographed\n",
      "epoch: 13, batch_loss: 3.924419641494751\n",
      "epoch: 13, batch_loss: 1.7725212574005127\n",
      "epoch: 13, batch_loss: 2.325535535812378\n",
      "epoch: 13, batch_loss: 2.8709332942962646\n",
      "epoch: 13, batch_loss: 2.1159820556640625\n",
      "Nearest to had: have has having been started\n",
      "Nearest to for: in closed gives planata one\n",
      "Nearest to being: venting contemptuous inactive pidgin keter\n",
      "Nearest to new: york transfered jyv free los\n",
      "Nearest to and: use in antiperspirants addictive synbranchiformes\n",
      "Nearest to two: undetectable sickle snowfalls three aryl\n",
      "Nearest to i: ii we buchner my ganguela\n",
      "Nearest to UNK: sidney jetranger isotherm meigs charles\n",
      "Nearest to up: put them move then cruentis\n",
      "Nearest to were: are shenzhou oxidised heider various\n",
      "Nearest to them: players him ways me we\n",
      "Nearest to use: and zoologist warrantless usage drogue\n",
      "Nearest to called: termed rejected known schlegel reflected\n",
      "Nearest to th: nd st rd century nineteenth\n",
      "Nearest to six: eight seven zero three five\n",
      "Nearest to was: overkill had be moses sviatopolk\n",
      "epoch: 13, batch_loss: 3.390967845916748\n",
      "epoch: 13, batch_loss: 3.8211703300476074\n",
      "epoch: 13, batch_loss: 2.641451597213745\n",
      "epoch: 13, batch_loss: 2.842644214630127\n",
      "epoch: 13, batch_loss: 4.650278091430664\n",
      "Nearest to had: has have was been having\n",
      "Nearest to for: final in international petrosains positioning\n",
      "Nearest to being: australische hippocrates were immoralities inflow\n",
      "Nearest to new: city york annus australia ilife\n",
      "Nearest to and: from shedding respectability worshippers germans\n",
      "Nearest to two: nine four eight ly five\n",
      "Nearest to i: ii iii eada oreca constantine\n",
      "Nearest to UNK: roxb recumbent mistress bra desierto\n",
      "Nearest to up: equipped dilithium alamanni plans analogs\n",
      "Nearest to were: are been all naturalists damon\n",
      "Nearest to them: bled gathered binds nutmeg judaism\n",
      "Nearest to use: call end initial warrantless true\n",
      "Nearest to called: used awarded named worn represented\n",
      "Nearest to th: seven century circa nd june\n",
      "Nearest to six: four seven eight nine five\n",
      "Nearest to was: had is a were soon\n",
      "epoch: 14, batch_loss: 2.566185712814331\n",
      "epoch: 14, batch_loss: 2.2669925689697266\n",
      "epoch: 14, batch_loss: 1.9723780155181885\n",
      "epoch: 14, batch_loss: 1.7661964893341064\n",
      "epoch: 14, batch_loss: 3.24345064163208\n",
      "Nearest to had: have fled has over bellingham\n",
      "Nearest to for: is and in of perspective\n",
      "Nearest to being: them routinely bled funneled standoff\n",
      "Nearest to new: ships magazine iic democracies decline\n",
      "Nearest to and: the of in for alaric\n",
      "Nearest to two: four one bc six three\n",
      "Nearest to i: everybody t we iii they\n",
      "Nearest to UNK: polarity messianic metamath turboprops mythology\n",
      "Nearest to up: ocean just put yards fingerspelled\n",
      "Nearest to were: catholics have realaudio androids these\n",
      "Nearest to them: pondering us automorphisms communicate drayton\n",
      "Nearest to use: refer call jainism addition exploit\n",
      "Nearest to called: harkens considered anonymously recorded sgarthr\n",
      "Nearest to th: nd rd oilcrops five nine\n",
      "Nearest to six: eight five zero seven four\n",
      "Nearest to was: became morristown is his maculata\n",
      "epoch: 14, batch_loss: 4.803313255310059\n",
      "epoch: 14, batch_loss: 2.8345582485198975\n",
      "epoch: 14, batch_loss: 3.6926674842834473\n",
      "epoch: 14, batch_loss: 3.3225040435791016\n",
      "epoch: 14, batch_loss: 4.23366641998291\n",
      "Nearest to had: has previously was anymore have\n",
      "Nearest to for: two five aikidoka abraxas sculpting\n",
      "Nearest to being: britanniae both defintion fabric peach\n",
      "Nearest to new: york modern los angle all\n",
      "Nearest to and: to dear kerebos two laden\n",
      "Nearest to two: three five four nine seven\n",
      "Nearest to i: iii ii vegetarians t three\n",
      "Nearest to UNK: warhol gothic champvallon heloise spirulinasource\n",
      "Nearest to up: function orchestrations larger exaggerating out\n",
      "Nearest to were: are was been have be\n",
      "Nearest to them: him attempts interlinked beehives tribes\n",
      "Nearest to use: central because absence claimed call\n",
      "Nearest to called: fantasical birthstone cancelled ngn anonymously\n",
      "Nearest to th: st nd oilcrops january merrick\n",
      "Nearest to six: eight three nine four seven\n",
      "Nearest to was: is were been are has\n",
      "epoch: 14, batch_loss: 2.1863791942596436\n",
      "epoch: 14, batch_loss: 2.543470859527588\n",
      "epoch: 15, batch_loss: 2.540506362915039\n",
      "epoch: 15, batch_loss: 2.3796029090881348\n",
      "epoch: 15, batch_loss: 3.2405333518981934\n",
      "Nearest to had: has have having been during\n",
      "Nearest to for: temptation mortara judiciaries especially to\n",
      "Nearest to being: just posterity were complements sociological\n",
      "Nearest to new: york los mississippi antique unanimously\n",
      "Nearest to and: in over sorbic studios laudation\n",
      "Nearest to two: which city five axiomatized three\n",
      "Nearest to i: intricacies ii embrace chiron buacach\n",
      "Nearest to UNK: material lines excavation usarc synchronized\n",
      "Nearest to up: south steps raia dion defenceless\n",
      "Nearest to were: are being descent antigens nashir\n",
      "Nearest to them: individuals enabling communicate him nazism\n",
      "Nearest to use: technik occupation manufacture example usage\n",
      "Nearest to called: named mj signs cooled worn\n",
      "Nearest to th: st circa nd zero eight\n",
      "Nearest to six: five three seven eight acres\n",
      "Nearest to was: is odusseus counterexamples wedgwood officially\n",
      "epoch: 15, batch_loss: 2.4416890144348145\n",
      "epoch: 15, batch_loss: 2.745413303375244\n",
      "epoch: 15, batch_loss: 2.0497794151306152\n",
      "epoch: 15, batch_loss: 3.014019012451172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15, batch_loss: 2.7370412349700928\n",
      "Nearest to had: has have maintain was hold\n",
      "Nearest to for: as navigate resistible because property\n",
      "Nearest to being: was funneled yhwh adasaurus kesteven\n",
      "Nearest to new: york audi transfered etiology idea\n",
      "Nearest to and: on postmodernism beyond socialist charted\n",
      "Nearest to two: six swat seven natural macedon\n",
      "Nearest to i: comfortably embrace emulated iv ii\n",
      "Nearest to UNK: tter warhol astrum garland sipapu\n",
      "Nearest to up: me dion once kneel screaming\n",
      "Nearest to were: are turncoat rushers many residing\n",
      "Nearest to them: cars interception reacted hkia memnoch\n",
      "Nearest to use: absence sense accumulate exist worship\n",
      "Nearest to called: described used okinawan signed regarded\n",
      "Nearest to th: century nd rd centuries st\n",
      "Nearest to six: three zero seven eight ptarmigan\n",
      "Nearest to was: is had suspending being however\n",
      "epoch: 15, batch_loss: 2.925800323486328\n",
      "epoch: 15, batch_loss: 3.09213924407959\n",
      "epoch: 15, batch_loss: 3.2070226669311523\n",
      "epoch: 15, batch_loss: 2.3301620483398438\n",
      "epoch: 15, batch_loss: 1.8044575452804565\n",
      "Nearest to had: been has was himself vomited\n",
      "Nearest to for: farmaze decriminalization an cabaret dreamlike\n",
      "Nearest to being: as venting hippocrates archaistic correlations\n",
      "Nearest to new: york zealand south wales wto\n",
      "Nearest to and: was in either of the\n",
      "Nearest to two: three nine five six computerworld\n",
      "Nearest to i: ii iv iii vii erzurum\n",
      "Nearest to UNK: like plumage halep dener common\n",
      "Nearest to up: out back added yards them\n",
      "Nearest to were: are screens cabbalists pidgin jericho\n",
      "Nearest to them: saddle up gathered bled away\n",
      "Nearest to use: rehab asylum ballistics addition antidepressants\n",
      "Nearest to called: named referred admired envisioned trowels\n",
      "Nearest to th: century nine bessie rd ponens\n",
      "Nearest to six: nine five two harnack three\n",
      "Nearest to was: and is became his had\n",
      "epoch: 16, batch_loss: 3.0540199279785156\n",
      "epoch: 16, batch_loss: 2.8100075721740723\n",
      "epoch: 16, batch_loss: 2.9593381881713867\n",
      "epoch: 16, batch_loss: 1.963282585144043\n",
      "epoch: 16, batch_loss: 2.7171099185943604\n",
      "Nearest to had: has have been remind wants\n",
      "Nearest to for: from and skids as this\n",
      "Nearest to being: funneled him colloid peacemaker beings\n",
      "Nearest to new: aaargh york transfered silent magnificent\n",
      "Nearest to and: of in to poets dfki\n",
      "Nearest to two: five eight one three metatartaric\n",
      "Nearest to i: t just everybody klerk my\n",
      "Nearest to UNK: behrmann play artcyclopedia crew moss\n",
      "Nearest to up: yards return them lines fingerspelled\n",
      "Nearest to were: are been asteroids guns heider\n",
      "Nearest to them: nazism up nasser antipathy view\n",
      "Nearest to use: instances make renewal technik details\n",
      "Nearest to called: immorality harkens credited quadruple named\n",
      "Nearest to th: century eight nineteenth three mid\n",
      "Nearest to six: seven five eight l th\n",
      "Nearest to was: is of a he ramalingaswami\n",
      "epoch: 16, batch_loss: 2.9436981678009033\n",
      "epoch: 16, batch_loss: 0.9147375822067261\n",
      "epoch: 16, batch_loss: 3.441971778869629\n",
      "epoch: 16, batch_loss: 3.5345282554626465\n",
      "epoch: 16, batch_loss: 3.2184653282165527\n",
      "Nearest to had: has been frontrunner believe vomited\n",
      "Nearest to for: of farmaze is laxatives and\n",
      "Nearest to being: was were rosewall sipsey abbesses\n",
      "Nearest to new: york zealand promote pleistocene oklahoma\n",
      "Nearest to and: with dissolves is a in\n",
      "Nearest to two: nine four three six eight\n",
      "Nearest to i: senet we centerless didn e\n",
      "Nearest to UNK: champvallon diacritics buddha marin vane\n",
      "Nearest to up: alamanni damero down back ledge\n",
      "Nearest to were: are was their be been\n",
      "Nearest to them: him those baronial people bled\n",
      "Nearest to use: antidepressants uses nostratic first trilobite\n",
      "Nearest to called: credited quadruple sting carried call\n",
      "Nearest to th: four july august nd eighteenth\n",
      "Nearest to six: eight five four two km\n",
      "Nearest to was: is were by of tassel\n",
      "epoch: 16, batch_loss: 2.488302230834961\n",
      "epoch: 16, batch_loss: 1.8321914672851562\n",
      "epoch: 17, batch_loss: 2.9428491592407227\n",
      "epoch: 17, batch_loss: 3.2153542041778564\n",
      "epoch: 17, batch_loss: 1.3006062507629395\n",
      "Nearest to had: have has enrollment been expending\n",
      "Nearest to for: however alphabet installment predetermine in\n",
      "Nearest to being: were corrections endorsements britanniae way\n",
      "Nearest to new: york oregon mississippi showing transfered\n",
      "Nearest to and: in of the southern brazoria\n",
      "Nearest to two: three five four million one\n",
      "Nearest to i: you darbari do toinn emulated\n",
      "Nearest to UNK: agave var maguey ears beh\n",
      "Nearest to up: wants dion damero communicate acyclic\n",
      "Nearest to were: are being conveys be have\n",
      "Nearest to them: away people only him fit\n",
      "Nearest to use: application technik northwesterly warrantless oath\n",
      "Nearest to called: iaijutsu immorality titular lyricist named\n",
      "Nearest to th: nd zero st mudarra three\n",
      "Nearest to six: five eight three four one\n",
      "Nearest to was: is they has does scum\n",
      "epoch: 17, batch_loss: 3.5620622634887695\n",
      "epoch: 17, batch_loss: 2.469249725341797\n",
      "epoch: 17, batch_loss: 3.1260921955108643\n",
      "epoch: 17, batch_loss: 1.4416531324386597\n",
      "epoch: 17, batch_loss: 4.02744197845459\n",
      "Nearest to had: has been have again neared\n",
      "Nearest to for: midterm riba favorites concertos levied\n",
      "Nearest to being: haloed valium second posterity inflow\n",
      "Nearest to new: york oklahoma chihuahua idea bicameral\n",
      "Nearest to and: of in the production consumption\n",
      "Nearest to two: three seven four five kilsyth\n",
      "Nearest to i: ii we criticsed polls levellers\n",
      "Nearest to UNK: tter algebra misunderstand dialect piaget\n",
      "Nearest to up: down before spend kahroba decided\n",
      "Nearest to were: are was been boas bhaskara\n",
      "Nearest to them: finitely pupils quantisation elektron those\n",
      "Nearest to use: usage pheromones example understand terms\n",
      "Nearest to called: appointed referred tice chosen ashestiel\n",
      "Nearest to th: century rd sixteenth nd nineteenth\n",
      "Nearest to six: four five seven march three\n",
      "Nearest to was: he naipaul were kammerer hochstetter\n",
      "epoch: 17, batch_loss: 1.8185946941375732\n",
      "epoch: 17, batch_loss: 1.6815581321716309\n",
      "epoch: 17, batch_loss: 4.519415378570557\n",
      "epoch: 17, batch_loss: 3.4368438720703125\n",
      "epoch: 18, batch_loss: 6.224014759063721\n",
      "Nearest to had: has been having were diaspora\n",
      "Nearest to for: farmaze example while chalices individualist\n",
      "Nearest to being: indefinitely having replace pit venting\n",
      "Nearest to new: losing uncertainties churchmen york failures\n",
      "Nearest to and: of to anarcho atm anarchism\n",
      "Nearest to two: five three six four nine\n",
      "Nearest to i: ii btk iii devotees single\n",
      "Nearest to UNK: cookies melville veneris capshaw meesteriana\n",
      "Nearest to up: down receiver kahroba them deoxygenated\n",
      "Nearest to were: are all campaigns many had\n",
      "Nearest to them: blew cybele bled people canonesses\n",
      "Nearest to use: technik used preferred exploit require\n",
      "Nearest to called: named referred worn also anonymously\n",
      "Nearest to th: six century nine sixteenth waller\n",
      "Nearest to six: nine two th zero seven\n",
      "Nearest to was: is denunciation embarked asserts soon\n",
      "epoch: 18, batch_loss: 1.8879196643829346\n",
      "epoch: 18, batch_loss: 3.2188689708709717\n",
      "epoch: 18, batch_loss: 3.3218231201171875\n",
      "epoch: 18, batch_loss: 2.0851263999938965\n",
      "epoch: 18, batch_loss: 2.6609621047973633\n",
      "Nearest to had: has been incantations was could\n",
      "Nearest to for: as canceled proclivities recompensing pulsars\n",
      "Nearest to being: peacemaker requisite thessalians funneled are\n",
      "Nearest to new: york ada aaargh dunedin illyrian\n",
      "Nearest to and: of sobhuza john ostia nuts\n",
      "Nearest to two: six one freon thess seven\n",
      "Nearest to i: t toinn let ii grossdeutschland\n",
      "Nearest to UNK: brutal alexei unstacked ulrich encapsulation\n",
      "Nearest to up: front leg out calcination hillsides\n",
      "Nearest to were: sell heider newly are whiteland\n",
      "Nearest to them: sneak saddle nazism likely stab\n",
      "Nearest to use: pda brink first amplification fanaticism\n",
      "Nearest to called: named used admired harkens said\n",
      "Nearest to th: eight nd century five six\n",
      "Nearest to six: seven three five nine four\n",
      "Nearest to was: is had storm giampietro in\n",
      "epoch: 18, batch_loss: 3.805604934692383\n",
      "epoch: 18, batch_loss: 2.643320083618164\n",
      "epoch: 18, batch_loss: 3.2192471027374268\n",
      "epoch: 18, batch_loss: 4.047658920288086\n",
      "epoch: 18, batch_loss: 2.3949830532073975\n",
      "Nearest to had: been vomited would signified scruple\n",
      "Nearest to for: electronics with bringers communing as\n",
      "Nearest to being: rubout adasaurus having venting feuds\n",
      "Nearest to new: york jersey random full university\n",
      "Nearest to and: the of to in a\n",
      "Nearest to two: four five six eight three\n",
      "Nearest to i: crystallization ii iii carmaker dic\n",
      "Nearest to UNK: marker comoro asgaard afarensis upman\n",
      "Nearest to up: humblest bow gonna plotted challenge\n",
      "Nearest to were: are structures was they institutions\n",
      "Nearest to them: him appraised away memnoch mediate\n",
      "Nearest to use: absence original word severan hypocrite\n",
      "Nearest to called: admired viewed biomimetic orlovsky schlegel\n",
      "Nearest to th: century waller january carolinas years\n",
      "Nearest to six: eight five four three two\n",
      "Nearest to was: is were it pecuniarily consistently\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18, batch_loss: 2.2541916370391846\n",
      "epoch: 18, batch_loss: 2.073733329772949\n",
      "epoch: 19, batch_loss: 2.8434689044952393\n",
      "epoch: 19, batch_loss: 3.2795650959014893\n",
      "epoch: 19, batch_loss: 2.7318665981292725\n",
      "Nearest to had: have has could having so\n",
      "Nearest to for: to vivendi personal youthful dedicating\n",
      "Nearest to being: instantly men acounting keter emigrating\n",
      "Nearest to new: york jersey oregon mississippi zealand\n",
      "Nearest to and: by to eight uniti countries\n",
      "Nearest to two: seven three six one eight\n",
      "Nearest to i: t you ll ii toinn\n",
      "Nearest to UNK: agave cay jericho isles tilsit\n",
      "Nearest to up: serapeum down ocean petrochemical north\n",
      "Nearest to were: are comprise be hazlitt had\n",
      "Nearest to them: people saddle him enabling away\n",
      "Nearest to use: warrantless technik aspiring timber condensed\n",
      "Nearest to called: mccormack schlegel named herriman iaijutsu\n",
      "Nearest to th: nd century cityofathens rd nine\n",
      "Nearest to six: one seven two three eight\n",
      "Nearest to was: tapiau be pleads seipel rivaled\n",
      "epoch: 19, batch_loss: 2.4814260005950928\n",
      "epoch: 19, batch_loss: 2.3335399627685547\n",
      "epoch: 19, batch_loss: 1.9155704975128174\n",
      "epoch: 19, batch_loss: 2.3575680255889893\n",
      "epoch: 19, batch_loss: 3.1519453525543213\n",
      "Nearest to had: have has scruple knew agrippina\n",
      "Nearest to for: dualistic ewing palmiest riba time\n",
      "Nearest to being: aaronites posterity were acounting was\n",
      "Nearest to new: york geologic etiology chihuahua university\n",
      "Nearest to and: one percent subtext test semicolons\n",
      "Nearest to two: three four few five eight\n",
      "Nearest to i: you t iii we ii\n",
      "Nearest to UNK: magnum warhol redeemer pere tetrode\n",
      "Nearest to up: in deflection steps took kilogram\n",
      "Nearest to were: are was dualisms being is\n",
      "Nearest to them: statements nazism surmounted fluidity happiness\n",
      "Nearest to use: absence make context madmen pheromones\n",
      "Nearest to called: considered named orlovsky presented signed\n",
      "Nearest to th: century eighteenth nd january st\n",
      "Nearest to six: eight zero three seven four\n",
      "Nearest to was: is were rushers but myrrh\n",
      "epoch: 19, batch_loss: 2.688931703567505\n",
      "epoch: 19, batch_loss: 3.187716245651245\n",
      "epoch: 19, batch_loss: 2.2707860469818115\n",
      "epoch: 19, batch_loss: 4.127078533172607\n",
      "epoch: 20, batch_loss: 2.622663974761963\n",
      "Nearest to had: has have would already must\n",
      "Nearest to for: spade to dreaded as until\n",
      "Nearest to being: was acceptable northwesterly afar decease\n",
      "Nearest to new: south aaargh retinite mentuhotep eniro\n",
      "Nearest to and: of animexample the lincoln s\n",
      "Nearest to two: five nine four seven tines\n",
      "Nearest to i: you we any myself zygotes\n",
      "Nearest to UNK: molyneux lugar first ushering wentworth\n",
      "Nearest to up: together revive priyadarsi put plotted\n",
      "Nearest to were: containment are speciosa unguided olympiodorus\n",
      "Nearest to them: liza capitalists those huddling effort\n",
      "Nearest to use: heimwehr occupation call make northwesterly\n",
      "Nearest to called: named graveyards unicameral timor liked\n",
      "Nearest to th: rd eight century nd syne\n",
      "Nearest to six: five seven births july nine\n",
      "Nearest to was: became is being the had\n",
      "epoch: 20, batch_loss: 2.3669445514678955\n",
      "epoch: 20, batch_loss: 3.4941112995147705\n",
      "epoch: 20, batch_loss: 3.68583607673645\n",
      "epoch: 20, batch_loss: 1.3505738973617554\n",
      "epoch: 20, batch_loss: 1.900268316268921\n",
      "Nearest to had: has have never been knew\n",
      "Nearest to for: by as other from in\n",
      "Nearest to being: victims ethernet are men were\n",
      "Nearest to new: york scrimmage thutmose encryption aaargh\n",
      "Nearest to and: in the by reveal to\n",
      "Nearest to two: five seven six four rowboat\n",
      "Nearest to i: you t my ll we\n",
      "Nearest to UNK: metamath other eleazar by as\n",
      "Nearest to up: bound alamanni kneel bannon teamed\n",
      "Nearest to were: are was but rushers rosamund\n",
      "Nearest to them: hilary quantisation hut servant parallel\n",
      "Nearest to use: republic speak however babylonians confirms\n",
      "Nearest to called: harkens appealed widget presented named\n",
      "Nearest to th: century nd rd lawmaking nineteenth\n",
      "Nearest to six: seven three five eight nine\n",
      "Nearest to was: is halant chdd were preoccupied\n",
      "epoch: 20, batch_loss: 2.566565752029419\n",
      "epoch: 20, batch_loss: 1.7993626594543457\n",
      "epoch: 20, batch_loss: 4.181451320648193\n",
      "epoch: 20, batch_loss: 1.5057110786437988\n",
      "epoch: 20, batch_loss: 3.5690531730651855\n",
      "Nearest to had: diagnosing knew questionnaire chinn kahroba\n",
      "Nearest to for: perfume is farmaze judaeo to\n",
      "Nearest to being: ileo ethernet anchovies gargano bodies\n",
      "Nearest to new: oklahoma aab zealand york quadrangular\n",
      "Nearest to and: of in to yet the\n",
      "Nearest to two: five four three eight one\n",
      "Nearest to i: ii iii you intricacies obstinate\n",
      "Nearest to UNK: abby diacritics unorganized emulsion lays\n",
      "Nearest to up: bound docked distance spring anaximandros\n",
      "Nearest to were: are been murchison dyeing exist\n",
      "Nearest to them: up communicate anticipated players partner\n",
      "Nearest to use: mechanical coherence antigens versions hypocrite\n",
      "Nearest to called: named admired anonymously orlovsky upstart\n",
      "Nearest to th: rd cm calendar five january\n",
      "Nearest to six: eight nine zero five seven\n",
      "Nearest to was: is gielgud viaggio dumps baguio\n",
      "epoch: 20, batch_loss: 3.34564471244812\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    epochs = 20\n",
    "\n",
    "    batch_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch_data, batch_labels in train_data.next_batch():\n",
    "            batch_cnt += 1\n",
    "            _, loss_val = sess.run(\n",
    "                [optimizer, loss],\n",
    "                feed_dict={X: batch_data, Y: batch_labels})\n",
    "\n",
    "            # 每5000batch输出一次信息\n",
    "            if (batch_cnt+1) % 10000 == 0:\n",
    "                print('epoch: {}, batch_loss: {}'.format(\n",
    "                    epoch+1, loss_val))\n",
    "\n",
    "            if (batch_cnt+1) % 50000 == 0:\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = int2word[valid_examples[i]]\n",
    "                    top_k = 5\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                    log = 'Nearest to {}:'.format(valid_word)\n",
    "                    for k in range(top_k):\n",
    "                        sim_word = int2word[nearest[k]]\n",
    "                        log += ' {}'.format(sim_word)\n",
    "                    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
