{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset import load_mnist\n",
    "\n",
    "train_data,test_data=load_mnist(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class LeNet:\n",
    "    def __init__(self, n_features):\n",
    "        self._get_params(n_features)\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self._build_input_part()\n",
    "            self._build_LeNet()\n",
    "            self._build_other_part()\n",
    "            self._get_conf()\n",
    "\n",
    "    def _get_params(self, n_features):\n",
    "        self.unit_I = n_features    # 输入单元数，等于特征数\n",
    "\n",
    "        self.n_filters = [5, 16, 120]    # 卷积核数量\n",
    "        self.conv_sizes = [(5, 5), (5, 5), (1, 1)]    # 卷积核尺寸\n",
    "\n",
    "        self.pool_size = (2, 2)    # 池化核尺寸\n",
    "        self.strides = (2, 2)    # 核移动的步长\n",
    "\n",
    "        self.FC_size = 84    # 全连接层单元数\n",
    "\n",
    "        self.unit_O = 10    # 输出单元数，类别数\n",
    "\n",
    "        self.lr = 1e-3\n",
    "\n",
    "    def _build_input_part(self):\n",
    "        # 输入必须是可由用户指定的，所以设为placeholder\n",
    "        self.X = tf.placeholder(tf.float32,\n",
    "                                [None, self.unit_I])  # 数据的样本数不指定，只指定特征数\n",
    "        self.Y = tf.placeholder(tf.int64, [None])    # 目标值为列向量，int64为了兼容\n",
    "        # 转为图片格式送入模型，(n_samples,width,height,depth)\n",
    "        self.X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "        self.training = tf.placeholder_with_default(False, shape=[],\n",
    "                                                    name='training')\n",
    "\n",
    "    def _build_LeNet(self):\n",
    "        # 网络结构图\n",
    "        with tf.name_scope('LeNet-5'):\n",
    "            C1 = tf.layers.conv2d(self.X_img, filters=self.n_filters[0],\n",
    "                                  kernel_size=self.conv_sizes[0], padding='same',\n",
    "                                  activation=tf.nn.tanh, name='C1')\n",
    "            S2 = tf.layers.max_pooling2d(C1, pool_size=self.pool_size,\n",
    "                                         strides=self.strides, name='S2')\n",
    "            C3 = tf.layers.conv2d(S2, filters=self.n_filters[1],\n",
    "                                  kernel_size=self.conv_sizes[1],\n",
    "                                  activation=tf.nn.tanh, name='C3')\n",
    "            S4 = tf.layers.max_pooling2d(C3, pool_size=self.pool_size,\n",
    "                                         strides=self.strides, name='S4')\n",
    "            C5 = tf.layers.conv2d(S4, filters=self.n_filters[2],\n",
    "                                  kernel_size=self.conv_sizes[2],\n",
    "                                  activation=tf.nn.tanh, name='C5')\n",
    "            FC6 = tf.layers.dense(tf.layers.flatten(C5), self.FC_size,\n",
    "                                  activation=tf.nn.tanh)\n",
    "            # 最后一层直接输出logits，无激活函数\n",
    "            self.logits = tf.layers.dense(FC6, self.unit_O)\n",
    "\n",
    "    def _build_other_part(self):\n",
    "        # 评估图\n",
    "        with tf.name_scope('Eval'):\n",
    "            # 计算一维向量与onehot向量之间的损失\n",
    "            self.loss = tf.losses.sparse_softmax_cross_entropy(labels=self.Y,\n",
    "                                                               logits=self.logits)\n",
    "            self.predict = tf.argmax(self.logits, 1)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(tf.equal(self.predict,\n",
    "                                                            self.Y), tf.float32))\n",
    "\n",
    "        # 优化图\n",
    "        with tf.name_scope('train_op'):\n",
    "            self.train_op = tf.train.AdamOptimizer(self.lr) \\\n",
    "                .minimize(self.loss)\n",
    "\n",
    "    def _get_conf(self):\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True    # 按需使用显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-96ddbaef7832>:45: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-96ddbaef7832>:47: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-96ddbaef7832>:56: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-96ddbaef7832>:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "epoch: 2, batch_loss: 0.02880563959479332, batch_acc: 1.0\n",
      "epoch: 3, batch_loss: 0.03374693542718887, batch_acc: 0.984375\n",
      "epoch: 4, batch_loss: 0.10714340955018997, batch_acc: 0.953125\n",
      "epoch: 5, batch_loss: 0.02890532836318016, batch_acc: 0.984375\n",
      "epoch: 6, batch_loss: 0.005262815859168768, batch_acc: 1.0\n",
      "epoch: 6, test_acc: 0.989182710647583\n",
      "epoch: 7, batch_loss: 0.027181049808859825, batch_acc: 0.984375\n",
      "epoch: 8, batch_loss: 0.0011873330222442746, batch_acc: 1.0\n",
      "epoch: 9, batch_loss: 0.009423267096281052, batch_acc: 1.0\n",
      "epoch: 10, batch_loss: 0.01802813448011875, batch_acc: 0.984375\n",
      "epoch: 11, batch_loss: 0.005898267030715942, batch_acc: 1.0\n",
      "epoch: 11, test_acc: 0.9870793223381042\n",
      "epoch: 12, batch_loss: 0.0005232660914771259, batch_acc: 1.0\n",
      "epoch: 13, batch_loss: 0.0004399986064527184, batch_acc: 1.0\n",
      "epoch: 14, batch_loss: 0.026381351053714752, batch_acc: 0.984375\n",
      "epoch: 15, batch_loss: 0.0033823680132627487, batch_acc: 1.0\n",
      "epoch: 17, batch_loss: 0.0004028420662507415, batch_acc: 1.0\n",
      "epoch: 17, test_acc: 0.98828125\n",
      "epoch: 18, batch_loss: 0.0011613897513598204, batch_acc: 1.0\n",
      "epoch: 19, batch_loss: 0.038125716149806976, batch_acc: 0.984375\n",
      "epoch: 20, batch_loss: 0.0002806638949550688, batch_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = LeNet(train_data.n_features)\n",
    "\n",
    "with tf.Session(graph=model.graph, config=model.config) as sess:\n",
    "    sess.run(model.init)\n",
    "    epochs = 20\n",
    "\n",
    "    batch_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch_data, batch_labels in train_data.next_batch():\n",
    "            batch_cnt += 1\n",
    "            loss_val, acc_val, _ = sess.run([model.loss, model.accuracy, model.train_op],\n",
    "                                            feed_dict={model.X: batch_data,\n",
    "                                                       model.Y: batch_labels,\n",
    "                                                       model.training: True})\n",
    "\n",
    "            if (batch_cnt+1) % 1000 == 0:\n",
    "                print('epoch: {}, batch_loss: {}, batch_acc: {}'\n",
    "                      .format(epoch+1, loss_val, acc_val))\n",
    "\n",
    "            if (batch_cnt+1) % 5000 == 0:\n",
    "                all_test_acc_val = list()\n",
    "                for test_batch_data, test_batch_labels in test_data.next_batch():\n",
    "                    test_acc_val = sess.run([model.accuracy],\n",
    "                                            feed_dict={model.X: test_batch_data,\n",
    "                                                       model.Y: test_batch_labels})\n",
    "                    all_test_acc_val.append(test_acc_val)\n",
    "                test_acc = np.mean(all_test_acc_val)\n",
    "                print('epoch: {}, test_acc: {}'.format(epoch+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
