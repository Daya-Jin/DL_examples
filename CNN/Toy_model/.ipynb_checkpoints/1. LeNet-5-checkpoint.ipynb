{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "os.sys.path.append(os.path.dirname(os.path.abspath('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype uint8 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset import load_mnist\n",
    "\n",
    "train_data,test_data=load_mnist(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构设计\n",
    "LeNet-5的网络结构如下表所示：\n",
    "\n",
    "|kernel|n_kernel|padding|stride|\n",
    "|-|:-:|:-:|:-:|\n",
    "|Conv 5*5|5|2|1|\n",
    "|MaxPool 2*2|-|0|2|\n",
    "|Conv 5*5|16|0|1|\n",
    "|MaxPool 2*2|-|0|2|\n",
    "|Conv 1*1|120|0|1|\n",
    "|FC 84|-|-|-|\n",
    "|Output 10|-|-|-|\n",
    "\n",
    "网络结构代码见```../models.py```。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import LeNet\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.reset_default_graph()    # 重置默认图\n",
    "model = LeNet(train_data.n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/models.py:50: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/models.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/models.py:61: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/hujinzhi/DL_for_learner/CNN/models.py:62: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "epoch: 2, batch_loss: 0.032192081212997437, batch_acc: 1.0\n",
      "epoch: 3, batch_loss: 0.01372466515749693, batch_acc: 1.0\n",
      "epoch: 4, batch_loss: 0.06131809949874878, batch_acc: 0.984375\n",
      "epoch: 5, batch_loss: 0.0066209835931658745, batch_acc: 1.0\n",
      "epoch: 6, batch_loss: 0.0024678900372236967, batch_acc: 1.0\n",
      "epoch: 6, test_acc: 0.9894831776618958\n",
      "epoch: 7, batch_loss: 0.025714067742228508, batch_acc: 1.0\n",
      "epoch: 8, batch_loss: 0.029319606721401215, batch_acc: 0.984375\n",
      "epoch: 9, batch_loss: 0.010117537342011929, batch_acc: 1.0\n",
      "epoch: 10, batch_loss: 0.023129388689994812, batch_acc: 0.984375\n",
      "epoch: 11, batch_loss: 0.00929890014231205, batch_acc: 1.0\n",
      "epoch: 11, test_acc: 0.9876803159713745\n",
      "epoch: 12, batch_loss: 0.036431312561035156, batch_acc: 0.96875\n",
      "epoch: 13, batch_loss: 0.0008235451532527804, batch_acc: 1.0\n",
      "epoch: 14, batch_loss: 0.012314015999436378, batch_acc: 1.0\n",
      "epoch: 15, batch_loss: 0.0031126299872994423, batch_acc: 1.0\n",
      "epoch: 17, batch_loss: 0.0013137911446392536, batch_acc: 1.0\n",
      "epoch: 17, test_acc: 0.9883813858032227\n",
      "epoch: 18, batch_loss: 0.03152291849255562, batch_acc: 0.984375\n",
      "epoch: 19, batch_loss: 0.010950815863907337, batch_acc: 1.0\n",
      "epoch: 20, batch_loss: 0.000942107813898474, batch_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with tf.Session(graph=model.graph, config=model.config) as sess:\n",
    "    sess.run(model.init)\n",
    "    epochs = 20\n",
    "\n",
    "    batch_cnt = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch_data, batch_labels in train_data.next_batch():\n",
    "            batch_cnt += 1\n",
    "            loss_val, acc_val, _ = sess.run([model.loss, model.accuracy, model.train_op],\n",
    "                                            feed_dict={model.X: batch_data,\n",
    "                                                       model.Y: batch_labels,\n",
    "                                                       model.training: True})\n",
    "\n",
    "            if (batch_cnt+1) % 1000 == 0:\n",
    "                print('epoch: {}, batch_loss: {}, batch_acc: {}'\n",
    "                      .format(epoch+1, loss_val, acc_val))\n",
    "\n",
    "            if (batch_cnt+1) % 5000 == 0:\n",
    "                all_test_acc_val = list()\n",
    "                for test_batch_data, test_batch_labels in test_data.next_batch():\n",
    "                    test_acc_val = sess.run([model.accuracy],\n",
    "                                            feed_dict={model.X: test_batch_data,\n",
    "                                                       model.Y: test_batch_labels})\n",
    "                    all_test_acc_val.append(test_acc_val)\n",
    "                test_acc = np.mean(all_test_acc_val)\n",
    "                print('epoch: {}, test_acc: {}'.format(epoch+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
